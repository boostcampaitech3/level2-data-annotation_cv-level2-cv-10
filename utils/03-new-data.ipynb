{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9558eabc-c5ce-4931-b0a9-ca271aaae7d3",
   "metadata": {},
   "source": [
    "## 새로운 데이터 전처리 후 json으로 만들기\n",
    "- https://github.com/boostcampaitech2/data-annotation-cv-level3-cv-07/blob/master/utils/annotation-polygon.py\n",
    "- https://github.com/boostcampaitech2/data-annotation-cv-level3-cv-07/blob/master/utils/annotation_for_revised.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ac779d6-94ef-4a60-9d20-745059287058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f2511c74-0afc-4f71-a5e7-84334029fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_dir = \"/opt/ml/input/data/AIStages_ANN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "60703800-830b-47bc-a4f0-6ef5015335ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(osp.join(new_data_dir, 'dataset/annotation.json'), 'r') as f:\n",
    "    new_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bafff1fa-cda6-4940-8583-56651280d3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1288"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = new_data[\"images\"]\n",
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9eb2f62c-f306-4cbd-af21-fdbce9edc23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_tmp = copy.deepcopy(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9d484a62-c82a-4787-954c-c3da8092cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "cnt_normal = 0\n",
    "cnt_abnormal = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8ae9f2f4-3bb3-425d-a60c-a164ed86c46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1288/1288 [00:00<00:00, 11664.83it/s]\n"
     ]
    }
   ],
   "source": [
    "for img_name, img_info in tqdm(new_data.items()):\n",
    "    # 라벨링이 되어 있지 않은 경우 -> abnormal\n",
    "    # if img_info[\"words\"] == {}:\n",
    "    #     del new_data_tmp[img_name]\n",
    "    #     cnt_abnormal += 1\n",
    "    #     continue\n",
    "    \n",
    "    # 이미지에 단어가 10개 미만인 경우 -> abnormal \n",
    "    if len(img_info[\"words\"]) < 10: \n",
    "        del new_data_tmp[img_name]\n",
    "        cnt_abnormal += 1\n",
    "        continue\n",
    "    \n",
    "    for word, word_info in img_info[\"words\"].items():\n",
    "        # transcription이 없는 경우 or 공백이 있는 경우 제거 -> abnormal\n",
    "        if word_info['illegibility'] == False:\n",
    "            if word_info['transcription'] == \"\" or len(word_info['transcription'].split(' ')) > 1: \n",
    "                del new_data_tmp[img_name][\"words\"][word]\n",
    "                # word를 삭제하여 해당 image의 word가 모두 없어졌다면 image 자체를 삭제\n",
    "                if new_data_tmp[img_name][\"words\"] == {}:\n",
    "                    del new_data_tmp[img_name]\n",
    "                    cnt_abnormal += 1\n",
    "                continue\n",
    "        \n",
    "        # polygon을 이루는 point가 4개인 경우 -> normal\n",
    "        if len(img_info[\"words\"][word][\"points\"]) == 4:\n",
    "            cnt_normal += 1\n",
    "            continue\n",
    "        \n",
    "        # polygon을 이루는 point가 4개 미만인 경우 -> abnormal\n",
    "        elif len(img_info[\"words\"][word][\"points\"]) < 4:\n",
    "            del new_data_tmp[img_name][\"words\"][word]\n",
    "            \n",
    "            # word를 삭제하여 해당 image의 word가 모두 없어졌다면 image 자체를 삭제\n",
    "            if new_data_tmp[img_name][\"words\"] == {}:\n",
    "                del new_data_tmp[img_name]\n",
    "                cnt_abnormal += 1\n",
    "                continue\n",
    "                \n",
    "            \n",
    "        # polygon을 이루는 point가 4개 초과인 경우 -> rect 단위로 잘라서 넣는다.\n",
    "        else:\n",
    "            polygon_tmp = copy.deepcopy(new_data_tmp[img_name][\"words\"][word])\n",
    "            polygon_to_rect = copy.deepcopy(polygon_tmp)\n",
    "            polygon_to_rect[\"points\"] = []\n",
    "            for idx in range(len(img_info[\"words\"][word][\"points\"]) // 2 - 1):\n",
    "                polygon_to_rect[\"points\"].append(polygon_tmp[\"points\"][idx])\n",
    "                polygon_to_rect[\"points\"].append(polygon_tmp[\"points\"][idx+1])\n",
    "                polygon_to_rect[\"points\"].append(polygon_tmp[\"points\"][-idx-1])\n",
    "                polygon_to_rect[\"points\"].append(polygon_tmp[\"points\"][-idx])\n",
    "                new_data_tmp[img_name][\"words\"][word+f\"{idx+100}\"] = copy.deepcopy(polygon_to_rect)\n",
    "                polygon_to_rect[\"points\"] = []\n",
    "            del new_data_tmp[img_name][\"words\"][word]\n",
    "        \n",
    "            # word를 삭제하여 해당 image의 word가 모두 없어졌다면 image 자체를 삭제\n",
    "            if new_data_tmp[img_name][\"words\"] == {}:\n",
    "                del new_data_tmp[img_name]\n",
    "                cnt_abnormal += 1\n",
    "                continue\n",
    "            \n",
    "            cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "54255802-911a-4d06-9995-297d421aacc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal polygon count : 19037\n",
      "Deleted 760 over polygon\n",
      "Abnormal polygon count : 618\n"
     ]
    }
   ],
   "source": [
    "print(f'Normal polygon count : {cnt_normal}')\n",
    "print(f'Deleted {cnt} over polygon')\n",
    "print(f'Abnormal polygon count : {cnt_abnormal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3e2605b1-0fdd-4fd8-8f91-dc84dbad89e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a7d08010-19c5-44e6-bda1-7d39a3fd7c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = { \"images\": new_data_tmp }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dda733ba-757a-4984-9118-906586e4b3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_data[\"images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f1a0a1cf-d736-44db-83b8-c1fa0d7e7326",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo_dir = osp.join(new_data_dir, 'ufo')\n",
    "if not osp.exists(ufo_dir):\n",
    "        os.makedirs(ufo_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "32078a7e-3802-475f-ae63-3f4c8bf73432",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(osp.join(ufo_dir, 'train.json'), \"w\") as f:\n",
    "    json.dump(new_data, f, indent=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c5b359-258f-4ba8-b6a0-e866048c4b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
